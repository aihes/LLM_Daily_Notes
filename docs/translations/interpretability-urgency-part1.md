# 可解释性的紧迫性

*作者：Dario Amodei*  
*原文发表于2025年4月*  
*翻译：LLM Daily Notes 团队*

*原文链接：[The Urgency of Interpretability](https://www.darioamodei.com/post/the-urgency-of-interpretability)*

在我从事AI工作的十年间，我目睹了它从一个微小的学术领域发展成为可以说是世界上最重要的经济和地缘政治议题。在这段时间里，我学到的最重要的一课可能是：底层技术的进步势不可挡，它由太过强大而无法阻止的力量驱动，但它**发生的方式**——我们构建事物的顺序、我们选择的应用以及它如何向社会推广的细节——是完全可以改变的，通过这样做可以产生巨大的积极影响。我们不能**停下**这辆巴士，但我们可以**驾驶**它。过去，我曾写过关于以[对世界有益的方式部署AI](/essay/machines-of-loving-grace)的重要性，以及确保民主国家在专制国家之前[构建和掌握这项技术](/post/on-deepseek-and-export-controls)的重要性。**在过去几个月里，我越来越关注驾驶这辆巴士的另一个机会：一个由最近的一些进展开启的诱人可能性，即我们可以在模型达到压倒性力量水平之前，成功实现可解释性——也就是理解AI系统的内部工作原理。**

外行人常常惊讶并担忧地得知我们不理解自己创造的AI是如何工作的。他们的担忧是正确的：这种理解的缺乏在技术史上基本上是前所未有的。几年来，我们（Anthropic和整个领域）一直在尝试解决这个问题，创建一种类似于高精度和准确的MRI的工具，能够完全揭示AI模型的内部工作原理。这个目标常常感觉遥不可及，但最近的多项[突破](https://www.anthropic.com/research/auditing-hidden-objectives)和[进展](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)让我确信我们现在走在正确的道路上，并且有真正成功的机会。

与此同时，整个AI领域的发展比我们在可解释性方面的努力更为领先，并且本身也在快速发展。因此，如果我们希望可解释性能够及时成熟以发挥作用，我们必须快速行动。这篇文章为可解释性做了论证：它是什么，为什么有了它AI会发展得更好，以及我们所有人能做什么来帮助它在这场竞赛中获胜。

## 无知的危险

现代生成式AI系统的不透明性与传统软件有着根本的不同。如果一个普通的软件程序做了某事——例如，视频游戏中的角色说了一句台词，或者我的食品配送应用允许我给司机小费——它之所以做这些事情，是因为有人专门编程实现了这些功能。生成式AI**完全不是这样**。当生成式AI系统做某事时，比如总结一份财务文件，我们在具体或精确的层面上不知道它为什么做出这些选择——为什么它选择某些词而不是其他词，或者为什么它偶尔会犯错误，尽管通常是准确的。正如我的朋友和联合创始人Chris Olah[常说的](https://www.youtube.com/watch?v=TxhhMTOTMDg)，生成式AI系统更多是"培养"出来的，而不是"构建"出来的——它们的内部机制是"涌现"的，而不是直接设计的。这有点像培育一株植物或一个细菌群落：我们设定了指导和塑造生长的高级条件，但确切的结构如何涌现是不可预测的，也难以理解或解释。当我们查看这些系统内部时，我们看到的是数十亿数字组成的庞大矩阵。这些矩阵**以某种方式**计算重要的认知任务，但它们究竟如何做到这一点并不明显。

**与生成式AI相关的许多风险和担忧最终都是这种不透明性的后果，如果模型是可解释的，这些问题将更容易解决。** 例如，AI研究人员经常担心不对齐的系统可能会采取创造者不希望的有害行动。我们无法理解模型的内部机制，这意味着我们无法有意义地预测此类行为，因此难以排除它们；事实上，模型确实表现出意外的涌现行为，尽管尚未达到引起重大关注的程度。更微妙的是，同样的不透明性使得很难找到确凿的证据**支持**这些风险在大规模存在，这使得很难争取支持来解决它们——事实上，也很难确切知道它们有多危险。

要解决这些对齐风险的严重性，我们必须比现在更清晰地看到AI模型的内部。例如，一个主要的担忧是AI欺骗或寻求权力。AI训练的性质使得AI系统有可能自行发展出欺骗人类的能力和寻求权力的倾向，这是普通确定性软件永远不会有的；这种涌现性质也使得难以检测和缓解此类发展。但同样，我们从未在真实世界场景中看到过欺骗和寻求权力的确凿证据，因为我们无法"当场抓获"模型思考渴望权力、欺骗性的想法。我们剩下的只是模糊的理论论点，即欺骗或寻求权力可能有动机在训练过程中涌现，有些人认为这完全令人信服，而其他人则认为这荒谬得令人发笑。老实说，我能理解这两种反应，这可能是为什么关于这种风险的辩论变得如此两极化的线索。
